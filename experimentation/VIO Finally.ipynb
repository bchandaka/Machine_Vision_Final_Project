{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f73c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "from scipy.optimize import least_squares\n",
    "# from helperFunctions import genEulerZXZMatrix, minimizeReprojection, generate3DPoints\n",
    "from math import cos, sin\n",
    "# import inlierDetector\n",
    "import pykitti\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import least_squares\n",
    "sys.path.append('../')\n",
    "from utils.visualization import plotting\n",
    "from utils.visualization.video import play_trip\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807b8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CITE THIS CODE\n",
    "\n",
    "class VisualOdometry():\n",
    "    def __init__(self, dataset: pykitti.raw):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        self.K_l = self.dataset.calib.K_cam0\n",
    "        self.P_l = self.dataset.calib.P_rect_00\n",
    "        self.K_r = self.dataset.calib.K_cam1\n",
    "        self.P_r = self.dataset.calib.P_rect_10\n",
    "        \n",
    "        self.num_frames = len(self.dataset.cam0_files)\n",
    "        \n",
    "        self.gt_poses = np.zeros((self.num_frames, 3, 4))\n",
    "#         for i in range(self.num_frames):\n",
    "#             self.gt_poses[i] = self.dataset.oxts[i].T_w_imu[:3]\n",
    "        R,t_start = pykitti.utils.pose_from_oxts_packet(self.dataset.oxts[0].packet, scale=1)\n",
    "        for i in range(self.num_frames):\n",
    "            R, t = pykitti.utils.pose_from_oxts_packet(self.dataset.oxts[i].packet, scale=1)\n",
    "            t -=t_start\n",
    "            self.gt_poses[i][:3,:3] = R\n",
    "            self.gt_poses[i][:3,3] = t\n",
    "            \n",
    "        # self.images_l = self._load_images(os.path.join(self.dataset.data_path, 'image_00', 'data') )\n",
    "        # self.images_r = self._load_images(os.path.join(self.dataset.data_path, 'image_01', 'data') )\n",
    "        block = 11\n",
    "        P1 = block * block * 8\n",
    "        P2 = block * block * 32\n",
    "        self.disparity = cv2.StereoSGBM_create(minDisparity=0, numDisparities=32, blockSize=block, P1=P1, P2=P2)\n",
    "        # self.disparities = [\n",
    "        #     np.divide(self.disparity.compute(self.images_l[0], self.images_r[0]).astype(np.float32), 16)]\n",
    "        self.disparities = [\n",
    "            np.divide(self.disparity.compute(np.array(self.dataset.get_cam0(0)), np.array(self.dataset.get_cam1(0))).astype(np.float32), 16)]  \n",
    "        self.fastFeatures = cv2.FastFeatureDetector_create()\n",
    "\n",
    "        self.lk_params = dict(winSize=(15, 15),\n",
    "                              flags=cv2.MOTION_AFFINE,\n",
    "                              maxLevel=3,\n",
    "                              criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 50, 0.03))\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_calib(filepath):\n",
    "        \"\"\"\n",
    "        Loads the calibration of the camera\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath (str): The file path to the camera file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        K_l (ndarray): Intrinsic parameters for left camera. Shape (3,3)\n",
    "        P_l (ndarray): Projection matrix for left camera. Shape (3,4)\n",
    "        K_r (ndarray): Intrinsic parameters for right camera. Shape (3,3)\n",
    "        P_r (ndarray): Projection matrix for right camera. Shape (3,4)\n",
    "        \"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            params = np.fromstring(f.readline(), dtype=np.float64, sep=' ')\n",
    "            P_l = np.reshape(params, (3, 4))\n",
    "            K_l = P_l[0:3, 0:3]\n",
    "            params = np.fromstring(f.readline(), dtype=np.float64, sep=' ')\n",
    "            P_r = np.reshape(params, (3, 4))\n",
    "            K_r = P_r[0:3, 0:3]\n",
    "        return K_l, P_l, K_r, P_r\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_poses(filepath):\n",
    "        \"\"\"\n",
    "        Loads the GT poses\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath (str): The file path to the poses file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        poses (ndarray): The GT poses. Shape (n, 4, 4)\n",
    "        \"\"\"\n",
    "        poses = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                T = np.fromstring(line, dtype=np.float64, sep=' ')\n",
    "                T = T.reshape(3, 4)\n",
    "                T = np.vstack((T, [0, 0, 0, 1]))\n",
    "                poses.append(T)\n",
    "        return poses\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_images(filepath):\n",
    "        \"\"\"\n",
    "        Loads the images\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        filepath (str): The file path to image dir\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        images (list): grayscale images. Shape (n, height, width)\n",
    "        \"\"\"\n",
    "        image_paths = [os.path.join(filepath, file) for file in sorted(os.listdir(filepath))]\n",
    "        images = [cv2.imread(path, cv2.IMREAD_GRAYSCALE) for path in image_paths]\n",
    "        return images\n",
    "\n",
    "    @staticmethod\n",
    "    def _form_transf(R, t):\n",
    "        \"\"\"\n",
    "        Makes a transformation matrix from the given rotation matrix and translation vector\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        R (ndarray): The rotation matrix. Shape (3,3)\n",
    "        t (list): The translation vector. Shape (3)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        T (ndarray): The transformation matrix. Shape (4,4)\n",
    "        \"\"\"\n",
    "        T = np.eye(4, dtype=np.float64)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "\n",
    "    def reprojection_residuals(self, dof, q1, q2, Q1, Q2):\n",
    "        \"\"\"\n",
    "        Calculate the residuals\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dof (ndarray): Transformation between the two frames. First 3 elements are the rotation vector and the last 3 is the translation. Shape (6)\n",
    "        q1 (ndarray): Feature points in i-1'th image. Shape (n_points, 2)\n",
    "        q2 (ndarray): Feature points in i'th image. Shape (n_points, 2)\n",
    "        Q1 (ndarray): 3D points seen from the i-1'th image. Shape (n_points, 3)\n",
    "        Q2 (ndarray): 3D points seen from the i'th image. Shape (n_points, 3)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        residuals (ndarray): The residuals. In shape (2 * n_points * 2)\n",
    "        \"\"\"\n",
    "        # Get the rotation vector\n",
    "        r = dof[:3]\n",
    "        # Create the rotation matrix from the rotation vector\n",
    "        R, _ = cv2.Rodrigues(r)\n",
    "        # Get the translation vector\n",
    "        t = dof[3:]\n",
    "        # Create the transformation matrix from the rotation matrix and translation vector\n",
    "        transf = self._form_transf(R, t)\n",
    "\n",
    "        # Create the projection matrix for the i-1'th image and i'th image\n",
    "        f_projection = np.matmul(self.P_l, transf)\n",
    "        b_projection = np.matmul(self.P_l, np.linalg.inv(transf))\n",
    "\n",
    "        # Make the 3D points homogenize\n",
    "        ones = np.ones((q1.shape[0], 1))\n",
    "        Q1 = np.hstack([Q1, ones])\n",
    "        Q2 = np.hstack([Q2, ones])\n",
    "\n",
    "        # Project 3D points from i'th image to i-1'th image\n",
    "        q1_pred = Q2.dot(f_projection.T)\n",
    "        # Un-homogenize\n",
    "        q1_pred = q1_pred[:, :2].T / q1_pred[:, 2]\n",
    "\n",
    "        # Project 3D points from i-1'th image to i'th image\n",
    "        q2_pred = Q1.dot(b_projection.T)\n",
    "        # Un-homogenize\n",
    "        q2_pred = q2_pred[:, :2].T / q2_pred[:, 2]\n",
    "\n",
    "        # Calculate the residuals\n",
    "        residuals = np.vstack([q1_pred - q1.T, q2_pred - q2.T]).flatten()\n",
    "        return residuals\n",
    "\n",
    "    def get_tiled_keypoints(self, img, tile_h, tile_w):\n",
    "        \"\"\"\n",
    "        Splits the image into tiles and detects the 10 best keypoints in each tile\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img (ndarray): The image to find keypoints in. Shape (height, width)\n",
    "        tile_h (int): The tile height\n",
    "        tile_w (int): The tile width\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        kp_list (ndarray): A 1-D list of all keypoints. Shape (n_keypoints)\n",
    "        \"\"\"\n",
    "        def get_kps(x, y):\n",
    "            # Get the image tile\n",
    "            impatch = img[y:y + tile_h, x:x + tile_w]\n",
    "\n",
    "            # Detect keypoints\n",
    "            keypoints = self.fastFeatures.detect(impatch)\n",
    "\n",
    "            # Correct the coordinate for the point\n",
    "            for pt in keypoints:\n",
    "                pt.pt = (pt.pt[0] + x, pt.pt[1] + y)\n",
    "\n",
    "            # Get the 10 best keypoints\n",
    "            if len(keypoints) > 10:\n",
    "                keypoints = sorted(keypoints, key=lambda x: -x.response)\n",
    "                return keypoints[:10]\n",
    "            return keypoints\n",
    "        # Get the image height and width\n",
    "        h, w, *_ = img.shape\n",
    "\n",
    "        # Get the keypoints for each of the tiles\n",
    "        kp_list = [get_kps(x, y) for y in range(0, h, tile_h) for x in range(0, w, tile_w)]\n",
    "\n",
    "        # Flatten the keypoint list\n",
    "        kp_list_flatten = np.concatenate(kp_list)\n",
    "        return kp_list_flatten\n",
    "\n",
    "    def track_keypoints(self, img1, img2, kp1, max_error=4):\n",
    "        \"\"\"\n",
    "        Tracks the keypoints between frames\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img1 (ndarray): i-1'th image. Shape (height, width)\n",
    "        img2 (ndarray): i'th image. Shape (height, width)\n",
    "        kp1 (ndarray): Keypoints in the i-1'th image. Shape (n_keypoints)\n",
    "        max_error (float): The maximum acceptable error\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        trackpoints1 (ndarray): The tracked keypoints for the i-1'th image. Shape (n_keypoints_match, 2)\n",
    "        trackpoints2 (ndarray): The tracked keypoints for the i'th image. Shape (n_keypoints_match, 2)\n",
    "        \"\"\"\n",
    "        # Convert the keypoints into a vector of points and expand the dims so we can select the good ones\n",
    "        trackpoints1 = np.expand_dims(cv2.KeyPoint_convert(kp1), axis=1)\n",
    "\n",
    "        # Use optical flow to find tracked counterparts\n",
    "        trackpoints2, st, err = cv2.calcOpticalFlowPyrLK(img1, img2, trackpoints1, None, **self.lk_params)\n",
    "\n",
    "        # Convert the status vector to boolean so we can use it as a mask\n",
    "        trackable = st.astype(bool)\n",
    "\n",
    "        # Create a maks there selects the keypoints there was trackable and under the max error\n",
    "        under_thresh = np.where(err[trackable] < max_error, True, False)\n",
    "\n",
    "        # Use the mask to select the keypoints\n",
    "        trackpoints1 = trackpoints1[trackable][under_thresh]\n",
    "        trackpoints2 = np.around(trackpoints2[trackable][under_thresh])\n",
    "\n",
    "        # Remove the keypoints there is outside the image\n",
    "        h, w = img1.shape\n",
    "        in_bounds = np.where(np.logical_and(trackpoints2[:, 1] < h, trackpoints2[:, 0] < w), True, False)\n",
    "        trackpoints1 = trackpoints1[in_bounds]\n",
    "        trackpoints2 = trackpoints2[in_bounds]\n",
    "\n",
    "        return trackpoints1, trackpoints2\n",
    "\n",
    "    def calculate_right_qs(self, q1, q2, disp1, disp2, min_disp=0.0, max_disp=100.0):\n",
    "        \"\"\"\n",
    "        Calculates the right keypoints (feature points)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        q1 (ndarray): Feature points in i-1'th left image. In shape (n_points, 2)\n",
    "        q2 (ndarray): Feature points in i'th left image. In shape (n_points, 2)\n",
    "        disp1 (ndarray): Disparity i-1'th image per. Shape (height, width)\n",
    "        disp2 (ndarray): Disparity i'th image per. Shape (height, width)\n",
    "        min_disp (float): The minimum disparity\n",
    "        max_disp (float): The maximum disparity\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        q1_l (ndarray): Feature points in i-1'th left image. In shape (n_in_bounds, 2)\n",
    "        q1_r (ndarray): Feature points in i-1'th right image. In shape (n_in_bounds, 2)\n",
    "        q2_l (ndarray): Feature points in i'th left image. In shape (n_in_bounds, 2)\n",
    "        q2_r (ndarray): Feature points in i'th right image. In shape (n_in_bounds, 2)\n",
    "        \"\"\"\n",
    "        def get_idxs(q, disp):\n",
    "            q_idx = q.astype(int)\n",
    "            disp = disp.T[q_idx[:, 0], q_idx[:, 1]]\n",
    "            return disp, np.where(np.logical_and(min_disp < disp, disp < max_disp), True, False)\n",
    "        \n",
    "        # Get the disparity's for the feature points and mask for min_disp & max_disp\n",
    "        disp1, mask1 = get_idxs(q1, disp1)\n",
    "        disp2, mask2 = get_idxs(q2, disp2)\n",
    "        \n",
    "        # Combine the masks \n",
    "        in_bounds = np.logical_and(mask1, mask2)\n",
    "        \n",
    "        # Get the feature points and disparity's there was in bounds\n",
    "        q1_l, q2_l, disp1, disp2 = q1[in_bounds], q2[in_bounds], disp1[in_bounds], disp2[in_bounds]\n",
    "        \n",
    "        # Calculate the right feature points \n",
    "        q1_r, q2_r = np.copy(q1_l), np.copy(q2_l)\n",
    "        q1_r[:, 0] -= disp1\n",
    "        q2_r[:, 0] -= disp2\n",
    "        \n",
    "        return q1_l, q1_r, q2_l, q2_r\n",
    "\n",
    "    def calc_3d(self, q1_l, q1_r, q2_l, q2_r):\n",
    "        \"\"\"\n",
    "        Triangulate points from both images \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        q1_l (ndarray): Feature points in i-1'th left image. In shape (n, 2)\n",
    "        q1_r (ndarray): Feature points in i-1'th right image. In shape (n, 2)\n",
    "        q2_l (ndarray): Feature points in i'th left image. In shape (n, 2)\n",
    "        q2_r (ndarray): Feature points in i'th right image. In shape (n, 2)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Q1 (ndarray): 3D points seen from the i-1'th image. In shape (n, 3)\n",
    "        Q2 (ndarray): 3D points seen from the i'th image. In shape (n, 3)\n",
    "        \"\"\"\n",
    "        # Triangulate points from i-1'th image\n",
    "        Q1 = cv2.triangulatePoints(self.P_l, self.P_r, q1_l.T, q1_r.T)\n",
    "        # Un-homogenize\n",
    "        Q1 = np.transpose(Q1[:3] / Q1[3])\n",
    "\n",
    "        # Triangulate points from i'th image\n",
    "        Q2 = cv2.triangulatePoints(self.P_l, self.P_r, q2_l.T, q2_r.T)\n",
    "        # Un-homogenize\n",
    "        Q2 = np.transpose(Q2[:3] / Q2[3])\n",
    "        return Q1, Q2\n",
    "\n",
    "    def estimate_pose(self, q1, q2, Q1, Q2, max_iter=100):\n",
    "        \"\"\"\n",
    "        Estimates the transformation matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        q1 (ndarray): Feature points in i-1'th image. Shape (n, 2)\n",
    "        q2 (ndarray): Feature points in i'th image. Shape (n, 2)\n",
    "        Q1 (ndarray): 3D points seen from the i-1'th image. Shape (n, 3)\n",
    "        Q2 (ndarray): 3D points seen from the i'th image. Shape (n, 3)\n",
    "        max_iter (int): The maximum number of iterations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformation_matrix (ndarray): The transformation matrix. Shape (4,4)\n",
    "        \"\"\"\n",
    "        early_termination_threshold = 5\n",
    "\n",
    "        # Initialize the min_error and early_termination counter\n",
    "        min_error = float('inf')\n",
    "        early_termination = 0\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            # Choose 6 random feature points\n",
    "            sample_idx = np.random.choice(range(q1.shape[0]), 6)\n",
    "            sample_q1, sample_q2, sample_Q1, sample_Q2 = q1[sample_idx], q2[sample_idx], Q1[sample_idx], Q2[sample_idx]\n",
    "\n",
    "            # Make the start guess\n",
    "            in_guess = np.zeros(6)\n",
    "            # Perform least squares optimization\n",
    "            opt_res = least_squares(self.reprojection_residuals, in_guess, method='lm', max_nfev=200,\n",
    "                                    args=(sample_q1, sample_q2, sample_Q1, sample_Q2))\n",
    "\n",
    "            # Calculate the error for the optimized transformation\n",
    "            error = self.reprojection_residuals(opt_res.x, q1, q2, Q1, Q2)\n",
    "            error = error.reshape((Q1.shape[0] * 2, 2))\n",
    "            error = np.sum(np.linalg.norm(error, axis=1))\n",
    "\n",
    "            # Check if the error is less the the current min error. Save the result if it is\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                out_pose = opt_res.x\n",
    "                early_termination = 0\n",
    "            else:\n",
    "                early_termination += 1\n",
    "            if early_termination == early_termination_threshold:\n",
    "                # If we have not fund any better result in early_termination_threshold iterations\n",
    "                break\n",
    "\n",
    "        # Get the rotation vector\n",
    "        r = out_pose[:3]\n",
    "        # Make the rotation matrix\n",
    "        R, _ = cv2.Rodrigues(r)\n",
    "        # Get the translation vector\n",
    "        t = out_pose[3:]\n",
    "        # Make the transformation matrix\n",
    "        transformation_matrix = self._form_transf(R, t)\n",
    "        return transformation_matrix\n",
    "\n",
    "    def get_pose(self, i):\n",
    "        \"\"\"\n",
    "        Calculates the transformation matrix for the i'th frame\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        i (int): Frame index\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        transformation_matrix (ndarray): The transformation matrix. Shape (4,4)\n",
    "        \"\"\"\n",
    "        # Get the i-1'th image and i'th image\n",
    "        # img1_l, img2_l = self.images_l[i - 1:i + 1]\n",
    "        img1_l = np.array(self.dataset.get_cam0(i-1))\n",
    "        img2_l = np.array(self.dataset.get_cam0(i))\n",
    "        # Get the tiled keypoints\n",
    "        kp1_l = self.get_tiled_keypoints(img1_l, 10, 20)\n",
    "\n",
    "        # Track the keypoints\n",
    "        tp1_l, tp2_l = self.track_keypoints(img1_l, img2_l, kp1_l)\n",
    "\n",
    "        # Calculate the disparitie\n",
    "        # self.disparities.append(np.divide(self.disparity.compute(img2_l, self.images_r[i]).astype(np.float32), 16))\n",
    "        img2_r = np.array(self.dataset.get_cam1(i))\n",
    "        self.disparities.append(np.divide(self.disparity.compute(img2_l, img2_r).astype(np.float32), 16))\n",
    "        # Calculate the right keypoints\n",
    "        tp1_l, tp1_r, tp2_l, tp2_r = self.calculate_right_qs(tp1_l, tp2_l, self.disparities[i - 1], self.disparities[i])\n",
    "\n",
    "        # Calculate the 3D points\n",
    "        Q1, Q2 = self.calc_3d(tp1_l, tp1_r, tp2_l, tp2_r)\n",
    "\n",
    "        # Estimate the transformation matrix\n",
    "        transformation_matrix = self.estimate_pose(tp1_l, tp2_l, Q1, Q2)\n",
    "        return transformation_matrix\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_dir = '../data/'  # Try KITTI_sequence_2\n",
    "    date = '2011_10_03'\n",
    "    drive = '0027'\n",
    "    dataset = pykitti.raw(data_dir, date, drive)\n",
    "\n",
    "    vo = VisualOdometry(dataset)\n",
    "\n",
    "    # play_trip(vo.images_l, vo.images_r)  # Comment out to not play the trip\n",
    "    degree = 30\n",
    "    r = np.array(R.from_euler('z', degree, degrees=True).as_matrix())\n",
    "    gt_path = []\n",
    "    estimated_path = []\n",
    "    for i, gt_pose in enumerate(tqdm(vo.gt_poses[:100], unit=\"poses\")):\n",
    "        if i < 1:\n",
    "            cur_pose = gt_pose\n",
    "        else:\n",
    "            transf = vo.get_pose(i)\n",
    "            cur_pose = np.matmul(cur_pose, transf)\n",
    "        gt_t = gt_pose[:3, 3]\n",
    "        gt_t = r @ gt_t\n",
    "#         print(gt_pose)\n",
    "#         if i == 2: break\n",
    "        # gt_path.append((gt_pose[0, 3], gt_pose[1, 3]))\n",
    "        gt_path.append((gt_t[0], gt_t[1]))\n",
    "        Tr = vo.dataset.calib.T_cam0_imu.round(4)\n",
    "#         cur_pose = Tr @ cur_pose\n",
    "        new_cur_pose = Tr @ np.vstack((cur_pose,np.array([0,0,0,1])))\n",
    "        # print(\"pose\", gt_t, cur_pose[:3,3])\n",
    "        estimated_path.append((cur_pose[0, 3],cur_pose[2, 3]))\n",
    "    plotting.visualize_paths(gt_path, estimated_path, \"Stereo Visual Odometry\",\n",
    "                             file_out=os.path.basename(data_dir) + \".html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c06e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a856e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'  # Try KITTI_sequence_2\n",
    "date = '2011_10_03'\n",
    "drive = '0027'\n",
    "dataset = pykitti.raw(data_dir, date, drive)\n",
    "vo = VisualOdometry(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e401f92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.35poses/s]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b5cdd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0012, -1.    ,  0.0067, -0.3254],\n",
       "       [-0.0092, -0.0067, -0.9999,  0.754 ],\n",
       "       [ 1.    ,  0.0011, -0.0092, -1.0949],\n",
       "       [ 0.    ,  0.    ,  0.    ,  1.    ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.calib.T_cam0_imu.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
